 ------------------------------------------------------------------------- %%
\chapter{Conceitos}
\label{cap:conceitos}
%% ------------------------------------------------------------------------- %%
\section{Computação em Nuvem}\index{Computação em nuvem!fundamentos}
\label{sec:computacaoEmNuvem}

A computação em nuvem refere-se tanto a aplicações fornecidas como serviços por meio da Internet como também a sistemas de hardware e software das CPDs(Centro de Processamento de Dados) que fornecem os serviços \cite{armbrust2009above}.

Como o termo nuvem é muito abrangente, ele foi dividido em várias classificações \cite{armbrust2009above}, entre elas, o tipo de serviço o qual fornecem. Nesse texto, quando falamos de nuvem, estaremos nos referindo a serviços que fornecem uma infraestrutura (IaaS). Cada infraestrutura pode receber várias requisições de hospedar programas de desenvolvedores e, nesse caso, terá que implantá-los em algum local no interior dela. Quando um cliente, em algum momento, faz uma requisição para executar esse programa, a nuvem executa o programa internamente e repassa o resultado ao cliente.

Para que isso seja possível, a infraestrutura de nuvem contém vários nós, os quais são recursos físicos como computadores e CPDs, que contém e controlam várias máquinas virtuais (MV) usando alguma técnica de virtualização. Cada requisição para implantar ou executar um programa é feita oferecendo as máquinas virtuais as quais estão dentro de um nó da infraestrutura.

\subsection{Uso da virtualização}\index{virtualização!aplicações da virtualização}

Na computação em nuvem, em particular quando se é fornecido uma infraestrutura para implantar aplicações(IaaS), a adoção da virtualização melhora a utilização dos recursos e protege o servidor de problemas que os softwares dos clientes possam causar em relação a servidores com máquinas puras \cite{chaudhary2008comparison}. 

Como consequência, também permite um novo modelo de negócio chamado ``pague somente quando usa'', onde o cliente paga somente pelo tempo que o recurso é usado. 
Além disso, o cliente tem a impressão de estar utilizando um ambiente com recursos infinitos, já que a configuração de uma máquina virtual pode ser ampliada sem interrupção do serviço e, mais máquinas podem ser agregadas para prover o serviço \cite{armbrust2009above}. 

Essas características beneficiam o lado do servidor, que não precisará fornecer um recurso físico inteiro para cada cliente e terá maior segurança e tolerância a falhas, já que cada sistema é independente. Do lado do cliente, ele irá economizar dinheiro pelo novo modelo de negócio e terá recursos sob demanda.

%% ------------------------------------------------------------------------- %%
\section{Virtualização}\index{virtualização!fundamentos}

\label{sec:virtualizacao}
\subsection{Virtualização de servidores}
Os servidores normalmente são constituídos de CPDs que estão ligados de alguma forma por uma rede. Quando queremos queremos fornecer recursos de maneira eficiente, uma tecnologia popularmente utilizada é a virtualização \cite{goncalvesresource}.
A virtualização divide um computador, geralmente com grande capacidade de processamento, em recursos menores chamados de máquinas virtuais de modo que cada uma age como se fosse um computador separado podendo ter inclusive diferentes sistemas operacionais \cite{barham2003xen}.

Com recursos menores, é possível fornecer ao consumidor uma quantidade menor de recursos computacionais que ainda satisfaçam seus requisitos e também alocar mais sob demanda \cite{armbrust2009above}.
Segundo \cite{chaudhary2008comparison}, as estratégias de virtualização podem ser divididas em 4 grandes categorias: virtualização completa, para-virtualização, virtualização em nível de sistema operacional e virtualização nativa.

Na virtualização completa também conhecida como emulação de hardware, um ou vários sistemas operacionais são executados dentro de um \textit{hypervisor}.
O \textit{hypervisor}, chamado também de gerenciador de máquinas virtuais, fornece uma plataforma para os sistemas operacionais das máquinas virtuais e gerencia a execução delas.

No \textit{hypervisor} da virtualização completa, é feita a interceptação, tradução e execução das instruções sob demanda dos sistemas operacionais das máquinas virtuais.
Nessa estratégia, o núcleo do sistema operacional que roda o \textit{hypervisor} não necessita de modificações. Dentro dessa categoria de \textit{hypervisores} estão o \textit{KVM}, o \textit{XEN}, o \textit{VMWare} e o \textit{VirtualBox}.

Diferente da virtualização completa, a para-virtualização exige uma modificação do núcleo para poder executar o \textit{hypervisor}. Assim, caso não exista o código-fonte do sistema, não é possível usar essa estratégia. Nele, o hardware virtual consegue conversar diretamente com o dispositivo emulado. Isso garante uma carga extra mínima em relação a tentar emular o dispositivo real. Nessa categoria estão incluídos o \textit{XEN}, o \textit{VMWare}.

A virtualização em nível de sistema operacional não tem um \textit{hypervisor}. Ela modifica o núcleo do sistema operacional isolando múltiplas instâncias do sistema operacional dentro de uma mesma máquina física. Nesse caso, como é feito apenas um isolamento entre as instâncias, estas ficam limitadas a usarem o mesmo sistema operacional. Está incluído nessa categoria o \textit{OpenVZ}.

Por fim, a virtualização nativa é uma virtualização completa melhorada. Ela aproveita o suporte de \textit{hardware} para virtualização dentro do próprio processador. Isto permite que múltiplos sistemas operacionais rodem sobre outros, sendo capazes de cada um acessar diretamente o processador do hospedeiro. Como exemplos temos o \textit{XEN}, o \textit{VMWare} e o \textit{VirtualBox}.

A virtualização completa e nativa tem uma grande vantagem em relação as outras: não é necessário alterar o núcleo do sistema. Isto as tornam mais simples e mais portável já que sistemas operacionais com código fechados podem usar usar elas.
 A para-virtualização e a virtualização em nível de sistema operacional exigem uma modificação no núcleo, porém, são as que tem um melhor desempenho pois elas têm acesso ao hardware físico. Comparando as duas, a virtualização em nível de sistema operacional é bem mais intrusivo e não permite a mudança do sistema operacional das máquinas virtuais, mas também tem um desempenho melhor que a para-virtualização \cite{chaudhary2008comparison}.


%% ------------------------------------------------------------------------- %%

\subsection{Virtualização de dispositivos de E/S}\index{virtualização!virtualização de dispositivos de E/S}

Com a virtualização de servidores, os dispositivos de E/S físicos passam a ter que sofrer modificações já que em um servidor não tem apenas um único sistema operacional, mas sim, várias máquinas virtuais com um sistema dentro de cada uma.

\cite{Rixner:2008:NVB:1348583.1348592} separou a virtualização de E/S em duas categorias: privada ou compartilhada.

Na virtualização de E/S privada, cada dispositivo físico é associado a apenas uma única MV enquanto que na virtualização de E/S compartilhada, o dispositivo é compartilhado para várias MV.

Comparando a virtualização de E/S privada com a compartilhada há uma subutilização na virtualização privada, pois parte do tempo em que a MV não usa o dispositivo é desperdiçada. Por outro lado, o desempenho da virtualização compartilhada é pior já que divide o recurso com outras máquinas.

Quando pensamos em escalar o número de MVs, o custo da virtualização privada se cresce absurdamente(com 10 MVs teríamos que ter 10 dispositivos físicos enquanto que na virtualização compartilhada,talvez até um dispositivo poderia ser o suficiente para resolver o problema).

Normalmente, queremos que o dispositivo físico seja compartilhado entre as máquinas, tanto pela possibilidade de escalar como pelo custo. Porém, disponibilizar de maneira compartilhada o acesso a dispositivos físicos pode trazer muitos problemas de segurança, dificultar o monitoramento das informações e a migração de máquinas virtuais \cite{Santos:2008:BGS:1404014.1404017}.

Para contornar esse problema, normalmente, \textit{hypervisores} como \textit{XEN}, \textit{KVM} e \textit{VMWare} restringem o acesso a um dispositivo físico para apenas uma máquina virtual e o acesso a esse dispositivo pelas outras máquinas virtuais é feito através dessa máquina. Essa restrição traz uma perda de desempenho em relação a ambientes que não usam virtualização quando o uso da rede é intensa, por exemplo \cite{chaudhary2008comparison} \cite{ekanayake2010high} \cite{liu2010evaluating}.\\


\cite{Waldspurger:2012:IV:2063176.2063194} fez algumas menções sobre o uso de técnicas de virtualização de E/S. Dentre as vantagens, ele cita a melhor utilização dos recursos e a economia de custos em relação a sistemas que estão com a implementação física acoplada com o dispositivo lógico, pois vários sistemas podem aproveitar o mesmo recurso. Em relação a flexibilidade, é possível mapear os dispositivos lógicos com as implementações físicas, garantindo uma maior portabilidade. Esse mapeamento pode também trazer novas funcionalidades ao recurso como: balanceamento da carga de trabalho e mascaramento das falhas. 

A funcionalidade de suspender, migrar e resumir uma máquina virtual também é possível, pois com o dispositivo lógico desacoplado da implementação física, é possível reconectar a máquina virtual em outra máquina física com uma configuração diferente.

Outra funcionalidade trazida com a virtualização é a interposição e transformação das requisições virtuais de E/S. Isso permite que as requisições que passam pelo dispositivo lógico sejam transformadas.
Em um exemplo de leitura e escrita no disco, além de simplesmente ler/escrever no disco, é possível guardar uma cópia da informação antiga como cópia de segurança para conseguir num momento futuro, "viajar no tempo" e desfazer algo que foi feito. Outra ideia é criptografar a informação quando alguém escrever no disco, dificultando outras pessoas de acessarem o seu conteúdo escrito.

%% ------------------------------------------------------------------------- %%
\subsection{Virtualização da Rede}\index{virtualização!virtualização da rede}

A virtualização de rede que também é um dispositivo de E/S tem algumas particularidades em relação a outros dispositivos.
Segundo \cite{Rixner:2008:NVB:1348583.1348592}, Comparando a virtualização de E/S com a virtualização de rede, a complexidade de virtualizar a rede é muito maior pelo fato de não se conhecer o destino de uma informação e a necessidade de estar preparado a qualquer momento para receber e responder ao tráfego da rede, diferentemente da virtualização de disco em que a leitura e escrita só ocorre quando requisitado pela máquina virtual.

%% ------------------------------------------------------------------------- %%
\subsection{Virtualização da Rede no XEN}\index{virtualização!xen}


Apesar da implementação dada ser específica para o XEN, outros \textit{hypervisores} como \textit{WMware} e \textit{KVM} adotam uma arquitetura semelhante \cite{Santos:2008:BGS:1404014.1404017}.

O \textit{dom0} ou domínio zero é a primeira máquina virtual iniciada pelo XEN. Ela tem certos privilégios que as outras máquinas virtuais não têm como iniciar novas máquinas e acessar o hardware diretamente. 
O \textit{domU} ou domínio do usuário são máquinas virtuais que, por padrão, não tem alguns privilégios que o \texttt{dom0} tem como o acesso direto ao \textit{hardware}. Assim, é necessário um mecanismo para conseguir acessar o dispositivo de rede.

No \textit{XEN}, para todas as máquinas conseguirem acessar o dispositivo de rede ao mesmo tempo, temos dois tipos de configuração: ponte e roteamento.

Como explica, \cite{xenenv}, na configuração de ponte, uma ponte virtual(\texttt{xenbr0}) é criada dentro do \texttt{dom0} como é possível ver na Figura \ref{ponte}.
Essa ponte está ligada na interface de rede física pela porta \texttt{peth0}. A porta \texttt{vif0.0} está sendo usada para tráfegos de/para \texttt{dom0} e as portas \texttt{vifX.0}, onde X é um valor maior que 0, estão sendo usadas para tráfegos de/para algum \texttt{domU}.
Como é possível observar, todo pacote que é recebido ou transmitido para alguma máquina virtual tem que passa pela ponte.

Na configuração de roteamento o \texttt{dom0} cria uma ligação entre ele e cada \texttt{domU}. Rotas de cada domU são adicionados na tabela de roteamento do \texttt{dom0}, nesse caso o \textit{IP} de cada  \textit{domU} tem que ser estático.\\

\begin{figure}[h!]
\begin{center}
  \includegraphics[width=192pt,height=148pt]{./img/Xen1.png}
\caption{ponte virtual criada no XEN \cite{xenenv}}
\label{ponte}
\end{center}
\end{figure}

Na Figura \ref{arq} vemos a arquitetura da virtualização da rede usando ponte no XEN. Para transmitir/receber um pacote no domínio hospedeiro(\texttt{domU}) é necessário usar o canal de E/S. Esse canal consiste de um mecanismo de notificação de evento e um \textit{buffer} de descrição em anel.

O mecanismo de notificação de evento avisa que alguém de um domínio escreveu no \textit{buffer} de E/S. Isso é feito através de uma interrupção virtual no outro domínio.

O buffer de descrição em anel guarda os detalhes de requisições entre o \textit{driver} de \textit{frontend}(\textit{netfront}) que fica no domínio que controla os \textit{drivers}(domínio do \textit{driver}) e o \textit{driver} de \textit{backend}(\textit{netback}) que fica dentro de um \texttt{domU}.

O domínio que controla os \textit{drivers}(domínio do \textit{driver}) por padrão é o \textit{dom0}. Porém, em alguns casos o \textit{driver} pode sobrecarregar o processamento do \textit{dom0}, então, as vezes, ele é separado em um domínio exclusivo.

\begin{figure}[h!]
\begin{center}
  \includegraphics[width=192pt,height=148pt]{./img/usenix08001.jpeg}
\caption{arquitetura da rede virtual no XEN \cite{Santos:2008:BGS:1404014.1404017}}
\label{arq}
\end{center}
\end{figure}

Para o domínio do \textit{driver} ter acesso ao \textit{buffer} de E/S dentro da memória do hospedeiro, é necessário um mecanismo de permissão. Neste, o domínio do hospedeiro fornece páginas da sua memória para serem usadas como \textit{buffer} de E/S. Essas páginas são passadas como referência na descrição da requisição.

Na transmissão, o \texttt{domU} coloca um pacote no \textit{buffer} de E/S e a sua página de referência no \textit{buffer} de descrição e notifica o domínio do \textit{driver}. Este então mapeia as páginas recebidas no seu espaço de endereços e pede para o dispositivo de E/S físico transmiti-la, quando o dispositivo o dispositivo termina a transmissão, o \texttt{domU} libera a página.

Na recepção, o domínio hospedeiro informa as possíveis páginas da memória que podem ser escritas e quando algum pacote chega pelo dispositivo físico, o dispositivo físico envia uma interrupção de chegada de pacote ao domínio do \textit{driver}, o \texttt{netback} o copia para uma página da memória que foi fornecida e envia uma interrupção para o \texttt{netfront}. Quando o \texttt{netfront} recebe uma notificação, ele pega oque está no \textit{buffer}, manda para o seu sistema e libera o buffer.


%% ------------------------------------------------------------------------- %%

\section{Mesclagem de Interrupções}\index{Mesclagem de interrupções}

Quando a recepção de pacotes é muito rápida no meio físico, a quantidade de interrupções devido a chegada de pacotes é muito grande podendo sobrecarregar o processamento.\cite{dong2011optimizing}.
Isso ocorre porque as interrupções têm prioridade absoluta sobre todas as outras tarefas e se a taxa de interrupções é suficientemente elevada, o sistema gastará todo seu tempo para respondê-la e o rendimento do sistema cairá para zero. \cite{salah2007coalesce}.

Várias soluções são propostas na literatura para resolver esse problema: mesclagem de interrupções \cite{salah2007coalesce},copia-zero \cite{Santos:2008:BGS:1404014.1404017}, \textit{scatter/gather} \cite{Corbet:2005:LDD:1209083}, \textit{TSO} \cite{gro}, \textit{GRO} \cite{gro}. 

O foco dessa pesquisa está na mesclagem de interrupções que pode ser feita através de um conjunto de parâmetros do \textit{driver} de redes.
O objetivo dele é reduzir a quantidade de interrupções na transmissão/recepção de pacotes dentro de um intervalo de tempo ou número de pacotes em troca de aumentar a latência da rede. 

Para isso é possível manipular 4 parâmetros, \texttt{tx-frames},\texttt{rx-frames},\texttt{tx-usecs},\texttt{rx-usecs}. A descrição de cada parâmetro está na tabela \ref{funcoes}.
Como pode-se notar a mesclagem de interrupções depende do tamanho do \textit{buffer} de transmissão e recepção.
O \textit{buffer} pode ser tanto um espaço de memória da máquina(usando DMA) como uma memória interna da placa de rede. Caso este seja pequeno, vários pacotes serão descartados durante o tráfego de pacotes por falta de espaço, caso seja grande, pode aumentar a latência por ter muitos pacotes esperando serem lidos dentro dele.

O NAPI \cite{Corbet:2005:LDD:1209083} é uma interface para usar técnicas de mesclagem de interrupções para dispositivo de rede no núcleo do Linux. O objetivo dele é reduzir a carga extra do processamento na recepção de pacotes.
 Para isso, no momento em que há uma grande quantidade de tráfego, ao invés do \textit{driver} gerar uma interrupção para cada pacote que recebe, o núcleo desabilita as interrupções e passa a checar continuamente a chegada de pacotes na rede e caso o sistema não dê conta de manipular os pacotes, ele passa a jogá-los fora antes de levá-los ao núcleo. 
Esse processo é chamado de \textit{polling}. Quando o tráfego é reduzido o núcleo volta a forma de recepção padrão.

{
\begin{table}[ht!]
\caption{Parâmetros para mesclagem de interrupções}
\label{funcoes}
\begin{center}
	\begin{tabular}{| cp{3.0cm} | l|}
		nome&&descrição\\
	\hline
	\texttt{tx-frame} N && gera uma interrupção quando a quantidade de pacotes \\&& dentro do buffer de transmissão chegar a N\\
	\texttt{rx-frame} N && gera uma interrupção quando a quantidade de pacotes \\&& dentro do buffer de recepção chegar a N\\
	\texttt{tx-usecs} N && gera uma interrupção N microssegundos depois que um \\&& pacote for transmitido\\
	\texttt{rx-usecs} N && gera uma interrupção N microssegundos depois que um \\&& pacote for recebido\\
	\end{tabular}
\end{center}
\end{table}
}

\subsection{Transmissão x Recepção}
Tanto a transmissão e a recepção de pacotes podem gerar interrupções com uma frequência grande. 
A transmissão gera uma interrupção quando um pacote é transmitido enquanto que a recepção gera uma interrupção quando um pacote é recebido.
A diferença entre eles é que enquanto a transmissão pode ser controlada pelo sistema, a recepção é mais complexa pois o pacote pode ter sido transmitido de fora.

\subsection{virtualização de rede}
No contexto da virtualização de rede, como foi possível ver na arquitetura da virtualização da rede no \textit{XEN}, muitos passos extras são feitos durante recepção e transmissão de pacotes, incluindo o aumento no número de interrupções. 

Na virtualização de rede do XEN, dois \textit{drivers} virtuais(\textit{frontend},\textit{backend}) são criados pelo próprio XEN para ligar o \texttt{dom0} com um \texttt{domU}.

A estratégia de mesclagem então pode ser feita tanto no \textit{driver} físico como no \textit{driver} virtual de \textit{frontend} e \textit{backend}.

\cite{dong2011optimizing} propuseram uma otimização por mesclagem de interrupções na recepção dentro dos \textit{drivers} virtuais. 
Os autores perceberam que o pacote passa por duas camadas de \textit{drivers} virtuais de rede antes de chegar no destino. O primeiro é o \textit{driver} de \textit{backend} que ficam na ponte e o outro é o driver de \textit{frontend} que está dentro da máquina virtual. 
Considerando estas duas camadas, a combinação de mesclagem de interrupções nas duas causaria um atraso adicional no envio.

Nessa pesquisa eles focaram em otimizar os \textit{drivers} virtuais, deixando de fora o \textit{driver} físico.


%Pela diversidade dos recursos que pode existir na nuvem, não é trivial escolher o recurso no qual será implantada a aplicação. Alguns recursos podem satisfazer os requisitos da aplicação, ou não.
% Dessa forma, quando é feita uma requisição para implantar um serviço, um componente da infraestrutura chamado escalonador deverá procurar e selecionar de forma inteligente uma ou mais MVs para implantar a aplicação. 
% O processo o qual o escalonador faz de buscar, selecionar e fornecer uma MV é chamado alocação de recursos e, nesse caso, o recurso que está sendo alocado é uma MV.
%Existem duas formas de selecionar um recurso: a priori e a posteriori. A priori, a primeira alocação do recurso já é a solução ótima. Já a posteriori, as soluções são sub-ótimas, assim, os recursos são 
%gerenciados continuamente, afim de tentar sempre satisfazer os requisitos da aplicação.\cite{goncalvesresource}

%\begin{figure}[h]
%\begin{center}
%  \includegraphics[width=60mm,height=60mm]{./img/resource_distance.png}
%\caption{Recursos interligados com largura de banda e atraso diferentes}
%\label{resource}
%\end{center}
%\end{figure}
%
%
%Nesse procedimento, a dinamicidade e os diferentes requerimentos da aplicação pode fazer com que os recursos (no caso as MVs) sejam mal usados \cite{goncalvesresource}.
%Como exemplo, se houver 3 recursos iguais com enlaces distintos como mostra na Figura \ref{resource}, 
%implantar uma aplicação no recurso 1 pode ser diferente de implantar no recurso 2 ou 3, pois ela pode querer se comunicar com alguma outra aplicação que está em outro recurso. 
%Nesse caso, se a aplicação tem requisitos de largura de banda ou tempo de resposta, essa escolha pode ajudar a respeitar ou não esses requisitos.
%
%
%Guiado pelos requerimentos do projeto CHOReOS\footnote{http://www.choreos.eu/bin/view/Main/}, os serviços os quais a nuvem terá que lidar, serão coreografias. Coreografia é um tipo de %composição de serviços, no qual cada serviço interage com outro sem um elemento central que coordena o processo como um todo. Ela só acontece quando cada participante executa seu papel. %Esse processo é chamado atuação. Na atuação, nós necessitamos implantar um conjunto de serviços que faça a coordenação entre papéis.
% Quando um serviço interage com outro através de um elemento central, nós a chamamos de orquestração. Semelhante a coreografia, na orquestração devemos implantar serviços para que a %composição possa ser executado. 

%O projeto CHOReOS irá implementar um arcabouço para o desenvolvimento de coreografias escaláveis. A meta desse projeto é possibilitar para experientes do domínio desenvolver soluções de %ultra-larga escala descentralizados, compostos de serviços heterogêneos que são adaptáveis e cientes da QoS. A priori, estas soluções são possíveis somente com a ajuda de dedicados %profissionais de TI fornecendo a habilidade necessária para arquitetura de design e engenharia de software.

%\cite{shouraboura2011placement} estudou o problema de alocar aplicações com o objetivo de reduzir a latência entre os recursos que precisam se comunicar. 
%Uma forma de conseguir resolver esse problema seria mapear a distância entre cada nó, porém,  a eficiência para mapear n nós é O(\begin{math} n^2\end{math}). %Como a latência pode mudar a qualquer momento, a quantidade de distância analisada pode variar bastante dependendo da rede e queremos uma informação em tempo real do que ocorre na rede %para alocar as aplicações rapidamente, melhorar a eficiência do algoritmo ajudaria a resolver melhor o problema.
% Nesse artigo foi elaborado um modelo para analisar a distâncias entre nós usando diagramas de voronoi o qual tem eficiência O(\begin{math}n\log{n}\end{math}).


%% ------------------------------------------------------------------------- %%


%%% ------------------------------------------------------------------------- %%
%\subsection{Simulação}
%
%Uma infraestrutura de nuvem pode conter vários nós, transparentes ou não, que possuem diferentes configurações e trocam mensagens por complexas topologias de redes, estas que variam bastante em relação a largura de banda e atraso. Isso torna a tarefa de fazer medições e elaborar teorias matemáticas difícil e complexa. 
%
%Assim, experimentos com simulação pode ser mais simples tanto pelo ambiente quanto pelo programa serem mais controláveis. Apesar disso, configurar as variáveis de um sistema inteiro seria uma tarefa que consome muito tempo, principalmente quando queremos fazer vários experimentos.
%Há duas propostas de ferramentas que ajudam na construção de simulações \cite{calheiros2011cloudsim} e \cite{casanova2008simgrid}.
%
%Cloudsim é um \textit{framework} para modelagem e simulação de infraestruturas em nuvem e serviços. No momento em que o testamos, ele não possuía suporte para aplicações paralelas e distribuídas.
%
%Simgrid é um \textit{framework} para execução de \textit{clusters}, grades e mecanismos P2P. Ele usa tarefas para executar a simulação. Tais tarefas tem um custo intrínseco para transmitir sobre a rede e um custo de execução.
